\documentclass{beamer}

\usepackage{igo}

\usetheme{Copenhagen}
\usecolortheme{default}

\title{Exploring Positional Linear Go}
\author[Weninger, Hayward]
{Noah Weninger \and Ryan Hayward}
\institute[University of Alberta]
{
  Department of Computing Science\\
  University of Alberta\\
  Canada
}
\date[ACG 2017]
{Advances in Computer Games, 2017}
\subject{Computing Science}

\begin{document}

    \frame{\titlepage}

    \begin{frame}
        \frametitle{Linear Go}
        Go on an $Nx1$ board.
        \bigskip
        % the monster
        \begin{center}
            \cleargoban
            \black{c2,d2}
            \white{f2,h2}
            \showgoban[b2,j2]
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Motivation}
        Solving Go is hard. Maybe $Nx1$ Go is easier and can lead to intuition about NxM Go?
        \begin{center}
            \textbf{Not necessarily. Some unique challenges arise.}
        \end{center}
    \end{frame}
    \begin{frame}
        \frametitle{Motivation}
        \begin{itemize}[<+->]
            \item Determine size of game graph vs number of cells on board.
            \item Something about safety... be careful to word this accurately.
            \item Cycles appear much more often on a linear board: ko rules play a more prominent role.
            \item Predicting the outcome of long and complex cycles is essential to playing well.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Positional Linear Go}
        We consider Tromp-Taylor rules with positional superko, no suicide and no komi. Game ends after 2 consecutive passes.
        \bigskip
        \begin{center}
            \cleargoban
            \showgoban[b2,h2]\\\medskip
            \pause
            \black{c2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \white{d2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \black{f2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \white{g2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \black{e2}
            \clear{d2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \white{d2}
            \clear{e2,f2}
            \showgoban[b2,h2]\\\medskip
            \pause
            \black[\igocross]{f2}
            \black[\igotriangle]{b2}
            \showgoban[b2,h2]\\\medskip
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{On rules}
        Previous work by Erik van der Werf, \textit{Solving Go for Rectangular Boards},
        describes a solver \textit{Migos} which uses different rules
        and solves $Nx1$ Go for $N$ up to 12.\\\medskip
        The rule set used by \textit{Migos} uses situational superko, and ... TODO
    \end{frame}

    \begin{frame}
        \frametitle{On rules}
        Difficulties in solving with positional superko
    \end{frame}

    \begin{frame}
        \frametitle{Our Goal}
        \begin{itemize}[<+->]
            \item Determine minimax value for many board sizes and opening moves.
            \item Understand some of the subtleties of Linear Go and develop intuition about how games progress.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Theorems \& other interesting results}
        Cell 2, telomere, full board, stable board, etc. go in this section
    \end{frame}

    \begin{frame}
        \frametitle{Definitions}
        \begin{itemize}[<+->]
            \item \textbf{Position} A board configuration.
            \item \textbf{State} A position, along with a set of positions that have been previously visited, and a flag to indicate whether the last move was a pass.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Cell 2}
        \begin{center}
            \cleargoban
            \black{b2}
            \showgoban[b2,k2]\ \ $\leq$
            \cleargoban
            \black{c2}
            \showgoban[b2,k2]
        \end{center}
        \begin{itemize}
            \item We say a stone $k$ away from an end of the board is in \textit{cell $k$}.
            \item \textbf{Conjecture 1.} If cells 1 and 2 have never been played
                in then playing in cell 2 is at least as good as playing in cell 1.
            \pause
            \item This has been verified for $N \leq 7$ by performing a search from the empty board which forks
                to test both decisions.
            \item It does not appear trivial to prove in general.
            %\item It is not trivial to prove in general because it is required to show that either there is always a path to the minimax value which does not depend on cell 1 being illegal due to superko, or that having cell 1 captured does not decrease the minimax value. ????
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{A weaker cell 2}
        \begin{center}
            \cleargoban
            \black[1]{b2}
            \white[2]{c2}
            \showgoban[b2,k2]\ \ $\leq$
            \cleargoban
            \white[2]{c2}
            \showgoban[b2,k2]
        \end{center}
        \begin{itemize}
            \item \textbf{Theorem 2.} If cells 1 and 2 have never been played
                in then passing is at least as good as playing in cell 1 and being immediately captured.
            \pause
            \item Proof sketch??
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Total states}
        \begin{center}
            \cleargoban
            \black{c2,f2,g2,h2,k2,m2,n2}
            \showgoban[b2,o2]\\\medskip
            \cleargoban
            \black{c2,d2,e2,g2,j2,l2,m2}
            \showgoban[b2,o2]
        \end{center}
        \begin{itemize}
            \item In some cases where the board is filled with stones of a single color
                except for a few gaps, we call this board \textit{total}.
            \item If the score of the current board is equal to the minimax value of the state,
                we call this state \textit{stable}.
            \pause
            \item \textbf{Theorem 4.} All states with total boards are stable.
            \item Pruning total states prevents the solver from wasting time by filling it's own eyes.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Loosely packed states}
        \begin{center}
            \cleargoban
            \black{c2,e2}
            \white{g2}
            \showgoban[b2,h2]\\\medskip
            \cleargoban
            \black{c2}
            \white{e2,f2}
            \showgoban[b2,g2]
        \end{center}
        \begin{itemize}
            \item A similar argument to theorem 4 holds even when both players have stones
                on the board. We call these states \textit{loosely packed}.
            \item \textbf{Theorem 5.} For $N\leq7$, all loosely packed states are stable.
            \pause
            \item This does \textbf{not} extend to $N>7$. For example consider this board
                where the score of the board is $+1$ but the minimax is $-1$:
        \end{itemize}
        \begin{center}
            \cleargoban
            \black{c2,e2}
            \white{g2,h2}
            \showgoban[b2,j2]
        \end{center}
    \end{frame}

    \begin{frame}
        \frametitle{Telomeres}
        \begin{itemize}
            \item When an end of the board matches certain patterns, we can prune some moves or provide bounds.
            \item \textbf{Theorem 6, 7, 8.}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Solver implementation}
        We implemented a solver using alpha-beta search with
        \begin{enumerate}
            \item Iterative deepening
            \item MTD($f$)
            \item Transposition tables
            \item Enhanced move ordering
            \item Knowledge based pruning
        \end{enumerate}
    \end{frame}

    \begin{frame}
        \frametitle{Iterative deepening}
        \begin{itemize}
            \item Perform many searches from the root while gradually increasing the depth cutoff.
            \item Since we want to solve the game exactly, care must be taken to correctly propagate exactness
                information up the tree: a node is exact iff the beta cutoff can be hit using some exact child,
                all children are exact, or it is a endgame leaf.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{MTD($f$)}
        \begin{itemize}
            \item Performs a series of null-window alpha-beta searches until converging on the minimax value.
            \item $f$ parameter is a guess which can improve convergence time.
            \item Iterative deepening gives us good guesses early on, so MTD($f$) can converge quickly:
                usually with less than two null-window searches.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Transposition tables}
        We use two separate transposition tables:

        A traditional $state \rightarrow bounds$ table and
            a $board \rightarrow move\ ordering$ table.
    \end{frame}

    \begin{frame}
        \frametitle{$state \rightarrow bounds$ table}
        \begin{itemize}
            \item Table needs to be indexed by a complete state to be correct.
            \item Difficult to implement efficiently and accurately because a state can be very
                large and of variable size: we store history using either a bitset or hash table, selected by
                board size.
            \item In our experience it is only useful when an entry represents a significant amount
                of work --- measured by subtree size --- and an exact node.
            \item Prevents iterative deepening and MTD($f$) from repeating work.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{$board \rightarrow move\ ordering$ table}
        \begin{itemize}
            \item Searching \textit{good} children first can speed up alpha-beta search.
            \item Good children are those that have:
                \begin{itemize}
                    \item Exact values: likely to be in the transposition table.
                    \item High scores: likely to cause a beta cutoff.
                    \item Small subtree size: estimated from previous iteration of iterative deepening.
                \end{itemize}
            \item These characteristics are chosen to minimize the time it takes to hit a beta cutoff.
            \item It is faster to index this table by the board instead of the state, but we need some policy
                to correct a possibly invalid move ordering because collisions can happen.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Knowledge based pruning}
        \begin{itemize}
            \item We use the theorems presented to prune nodes from the search.
            \item Unfortunately, we found that some pruning theorems actually increase the search time
                in some cases because they cause easily proven bounds to be skipped.
            \item Useful pruning theorems were those regarding cell 2, total states and loosely packed states.
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{Results}
        Empty board scores line up previous work by Van der Werf et al.

        We found scores for all opening moves on sizes up to 1x9.

        \begin{figure}[th]
        \begin{tabular}{|c|ccccccccc|} \hline
        n & \multicolumn{9}{c|}{minimax value by 1st-move location} \\ \hline
        2 & -2 & - &&&&&&& \\
        3 & -3 & 3 & - &&&&&& \\
        4 & -4 & 4 & - & - &&&&& \\
        5 & -5 & 0 & 0 & - & - &&&& \\
        6 & -6 & 1 & -1 & - & - & - &&&\\
        7 & -7 &  2 & -2 & 2 & - & - & - &&\\
        8 & -3 &  3 & -1 & 1 & - & - & - & - &\\
        9 & -4 & 0  & -1  & 0 & 0 & - & - & - & -\\ \hline
        \end{tabular}
        \caption{Missing entries follow by left-right symmetry.}\label{fig:1st_move_value}
        \label{fig:mmx}
        \end{figure}
    \end{frame}

\end{document}
